---
type: module
name: 'Athena Reporting - Salesforce Updater'
description: 'Module responsible for orchestrating data updates from Athena to Salesforce.'
product: 'Crossover: Hire'
scripts:
  check:
    - cwd: '.'
      script: 'npm run check'
  fix:
    - cwd: '.'
      script: 'npm run fix'
  test:
    - cwd: '.'
      script: 'npm run test'
files:
  sources:
    include:
      - 'sf-updater/**'
  iac:
    include:
      - 'deploy/src/**/*.ts'
---

# Context Pack - Crossover: Hire - L2 - Athena Reporting - Salesforce Updater

## Business Context

This module solves the business problem of keeping Salesforce data up-to-date with analytics generated in Athena. It enables a seamless workflow by automating the process of syncing data from Athena to Salesforce, ensuring that the CRM system reflects the latest insights. This is particularly relevant for key metrics like application data, campaign performance, and world map location stats.

## Functional Context

The module facilitates the transfer of data from Athena, where analytics are generated, to Salesforce, where this data is utilized for decision-making and reporting. It orchestrates a series of tasks, including:

- **Data Retrieval:** Queries Athena to retrieve the desired analytics data.
- **Data Transformation:** Optionally processes and transforms the retrieved data before sending it to Salesforce.
- **Data Upload:** Utilizes AWS AppFlow to securely and reliably send data to Salesforce.
- **Data Processing:** Performs post-processing operations on the updated Salesforce data, such as updating the E2E tracker or handling specific data updates for world map locations.

## Important Functional Decisions

- **Data Update Frequency:** Data updates are scheduled to occur on a weekly basis, balancing the need for fresh data with performance considerations.
- **Error Handling:** Robust error handling mechanisms are implemented to ensure that failures in the data update process are detected and addressed promptly. Notifications are sent to designated recipients for swift resolution.

## Technical Context

### Tech Stack

- **AWS Services:** The module leverages various AWS services, including:
  - **Athena:** For querying the analytics data stored in S3.
  - **Glue:** For transforming data from CSV to Orc format.
  - **Step Functions:** For orchestrating the data update process.
  - **AppFlow:** For securely and reliably uploading data to Salesforce.
  - **Lambda:** For executing specific data processing tasks and managing data file operations.
  - **S3:** For storing data files and managing data transfers.
  - **SNS:** For sending error notifications.
- **Salesforce:** The module interacts with Salesforce to update specific objects with the retrieved data.

### Architecture

```mermaid
graph LR
    subgraph Data Source
        A[Athena] --> B{Data Query}
    end
    B --> C[Data Transformation (Optional)]
    C --> D[Data Upload (AppFlow)]
    subgraph Salesforce Destination
        D --> E[Salesforce Objects]
    end
    subgraph Data Processing
        E --> F{Data Processing (Lambda)}
    end
    F --> G[E2E Tracker (Optional)]
    F --> H[World Map Location Updates (Optional)]
```

### Important Technical Decisions

- **Data Format:** The module utilizes CSV format for data exchange between Athena and AppFlow, ensuring compatibility and ease of handling.
- **Data Storage:** Data files are stored in S3 for efficient data management and accessibility.
- **Error Handling:** A dedicated error handling mechanism is implemented to capture failures and send notifications via SNS, enabling rapid resolution of issues.

### Established Practices

- **CI/CD:** The module employs CDK for infrastructure-as-code (IaC) management, enabling seamless deployment across environments.
- **Testing:** Comprehensive unit and integration tests are implemented to ensure the module's reliability and correctness.
- **Logging:** Detailed logging is incorporated to facilitate troubleshooting and monitoring.

### Additional Guidance

- When updating the AppFlow mapping schema (i.e. adding new fields) it is important for the source bucket to contain the csv data file with all fields during th deployment. Otherwise, the deployment will fail. Such file should be prepared and uploaded manually before the deployment.

### 3rd party services

- **OwnBackup:** Used for exporting Salesforce data backups to S3.

### 3rd party libraries

- **@trilogy-group/lambda-cdk-infra:** Provides infrastructure building blocks for Lambda functions and CDK deployments.

## Functions

- **`sf-updater-config.ts`:** Defines the configuration for the Salesforce Updater module, specifying Salesforce connector details, data flows, and other parameters. [L3: sf-updater-config.ts](sf-updater-config.ts.md)
- **`sf-updater-prepare.ts`:** Handles pre-deployment preparation tasks, such as building Lambda functions. [L3: sf-updater-prepare.ts](sf-updater-prepare.ts.md)
- **`sf-updater-stack.ts`:** Defines the main CDK stack for the Salesforce Updater, responsible for creating the required AWS resources, including S3 buckets, Lambda functions, and Step Functions. [L3: sf-updater-stack.ts](sf-updater-stack.ts.md)
- **`sf-updater-state-machine-stack.ts`:** Creates and configures the Step Function state machine that orchestrates the data update process. [L3: sf-updater-state-machine-stack.ts](sf-updater-state-machine-stack.ts.md)
